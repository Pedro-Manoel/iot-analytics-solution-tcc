<h1 align="center">
  <span> üìä Solu√ß√£o de IoT Analytics - TCC </span>
  <h3 align="center">
    <i> Ci√™ncia da Computa√ß√£o - UFCG</i>
  </h3>
</h1>

> Para mais detalhes sobre a solu√ß√£o, acesse o [TCC]().

## üìë Sum√°rio

- [Descri√ß√£o](#descricao)
- [Arquitetura](#arquitetura)
  - [Componentes](#componentes)
  - [Conteineriza√ß√£o](#docker)
  - [Fluxos](#fluxos)
- [Execu√ß√£o](#execucao)
- [Licen√ßa](#license)

## üìù Descri√ß√£o <a name = "descricao"></a>

Solu√ß√£o de IoT Analytics, desenvolvida como parte do Trabalho de Conclus√£o de Curso (TCC) do curso de Ci√™ncia da Computa√ß√£o da Universidade Federal de Campina Grande (UFCG), essa ferramenta foi projetada para trabalhar com sensores ambientais. Seu principal objetivo √© coletar, processar, armazenar, analisar e visualizar os dados m√©tricos do ambiente e dos pr√≥prios sensores em tempo real, al√©m de permitir an√°lises hist√≥ricas. Essa solu√ß√£o foi aplicada com sucesso √† [rede de sensores de qualidade do ar no estado do Acre](https://www.ufac.br/site/noticias/2023/projeto-desenvolvido-na-ufac-monitora-qualidade-do-ar-no-acre), Brasil. Isso serviu como um teste pr√°tico para verificar sua viabilidade e efic√°cia. 

### üì¶ Arquitetura <a name = "arquitetura"></a>
A arquitetura foi meticulosamente projetada seguindo os princ√≠pios de uma arquitetura de microsservi√ßos, proporcionando um sistema robusto e flex√≠vel, ideal para lidar com os desafios √∫nicos apresentados pelos dados da Internet das Coisas (IoT).

A arquitetura proposta √© composta por um conjunto de aplica√ß√µes, cada uma desempenhando um servi√ßo essencial. As principais aplica√ß√µes s√£o provenientes da [Funda√ß√£o Apache](https://www.apache.org/), uma respeitada organiza√ß√£o sem fins lucrativos dedicada a apoiar projetos de c√≥digo aberto. A escolha de utilizar exclusivamente componentes de c√≥digo aberto permite uma personaliza√ß√£o e flexibilidade sem precedentes, permitindo que a arquitetura seja adaptada para atender a uma variedade de necessidades.

Al√©m disso, a arquitetura foi constru√≠da para suportar caracter√≠sticas-chave no contexto de dados da IoT, como interoperabilidade, reutiliza√ß√£o e flexibilidade. Isso garante que a arquitetura possa se adaptar e evoluir √† medida que novas tecnologias e padr√µes emergem no campo em r√°pida evolu√ß√£o da IoT.

![Arquitetura no Docker](/.github/assets/images/architecture.png)

#### üõ†Ô∏è Componentes  <a name = "componentes"></a>
- [Apache NiFi](https://nifi.apache.org/): Esta aplica√ß√£o √© a respons√°vel pela ingest√£o de dados em tempo real.
- [Apache Kafka](https://kafka.apache.org/): Esta aplica√ß√£o √© a respons√°vel pelo gerenciamento e distribui√ß√£o dos diferentes fluxos de dados entre as aplica√ß√µes.
- [Apache Spark](https://spark.apache.org/): Esta aplica√ß√£o √© a respons√°vel pelo processamento de dados em tempo real.
- [Apache Druid](https://druid.apache.org/): Esta aplica√ß√£o √© a respons√°vel pelo armazenamento e pelas analises de dados em tempo real e em s√©rie hist√≥rica.
- [Apache Superset](https://superset.apache.org/): Esta aplica√ß√£o √© a respons√°vel pela visualiza√ß√£o dos dados em tempo real e em s√©rie hist√≥rica.
- [Node.js](https://nodejs.org/): Esta aplica√ß√£o foi utilizada para desenvolver servi√ßos auxiliares que s√£o utilizados pelo Apache NiFi.

#### ‚ú® Conteineriza√ß√£o <a name = "docker"></a>
Foi utilizado o [Docker](https://www.docker.com/) para empacotar cada aplica√ß√£o e suas depend√™ncias em um recipiente virtual. Cada componente (NiFi, Kafka, Spark, Druid, Superset e os Servi√ßos Node.js) tem um container dedicado, gerenciado por um arquivo Docker Compose. Foi criado um arquio Dockerfile espec√≠fico para os servi√ßos Node.js, contendo instru√ß√µes para construir suas respectivas imagens Docker.

Cada container cont√©m apenas os servi√ßos e ferramentas necess√°rios para seu funcionamento. Todos os containers s√£o executados na mesma rede, `iot_analytics`, para permitir a comunica√ß√£o entre eles. Os volumes de dados para cada aplica√ß√£o s√£o nomeados para garantir a persist√™ncia dos dados ao reiniciar a aplica√ß√£o.

### ‚öôÔ∏è Fluxos <a name = "fluxos"></a>

A arquitetura √© estruturada em quatro fluxos principais: **Ingest√£o**, **Processamento**, **Armazenamento** e **Visualiza√ß√£o**. Cada fluxo tem uma fun√ß√£o espec√≠fica e √© definido como a intera√ß√£o entre duas ou mais aplica√ß√µes que trabalham em conjunto para alcan√ßar um objetivo espec√≠fico.

**Fluxos da arquitetura**
![Fluxos da arquitetura](/.github/assets/images/streams.png)

>**Ingest√£o**

No fluxo de ingest√£o, o Apache NiFi √© encarregado de coletar os dados dos sensores da PurpleAir e envi√°-los para o Apache Kafka. O Kafka atua num sistema de produtor e consumidor, onde o Apache NiFi atua como produtor.

**Funcionamento do Kafka**
![Funcionmento do Kafka](/.github/assets/images/operation_kafka.png)


>**Processamento**

No fluxo de processamento, o Apache Kafka disponibiliza os dados brutos para o Apache Spark, especificamente o [Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html). O Spark processa esses dados e os envia de volta para o Apache Kafka. Neste cen√°rio, o Apache Spark atua como consumidor e produtor do Apache Kafka.


**Funcionamento do Spark Structured Streaming**
![Funcionamento do Spark Structured Streaming](/.github/assets/images/operation_spark.png)

>**Armazenamento**

No fluxo de armazenamento, o Apache Kafka disponibiliza os dados processados para o Apache Druid, que faz a ingest√£o e o armazenamento desses dados, disponibilizando-os para serem consultados e analisados.

**Funcionamento do Druid**
![Funcionamento do Druid](/.github/assets/images/operation_druid.png)

**Funcionamento da Integra√ß√£o do Kafka com o Druid**
![Funcionamento da Integra√ß√£o do Kafka com o Druid](/.github/assets/images/operation_kafka_and_druid.png)

>**Visualiza√ß√£o**

No fluxo de visualiza√ß√£o, o Apache Druid disponibiliza os dados para o Apache Superset, que permite a visualiza√ß√£o dos dados em tempo real e em s√©rie hist√≥rica. Atrav√©s dos dashboards, √© poss√≠vel visualizar os dados de qualidade do ar no Acre, entre outras m√©tricas e dados coletados.

**Dashboard de PM2.5 em Tempo Real**
![Dashboard de PM2.5 em Tempo Real](./.github/assets/images/dashboard_01.png)

**Dashboard de PM2.5 em S√©rie Hist√≥rica**
![Dashboard de PM2.5 em S√©rie Hist√≥rica](./.github/assets/images/dashboard_02.png)

**Dashboard de Status dos Sensores**
![Dashboard de Status dos Sensores](./.github/assets/images/dashboard_03.png)

**Dashboard de Dados Hist√≥ricos**
![Dashboard de Dados Hist√≥ricos](./.github/assets/images/dashboard_04.png)


### üöÄ Execu√ß√£o <a name = "execucao"></a>

Para facilitar a execu√ß√£o do projeto, foi criado um [Makefile](https://makefiletutorial.com/). O Makefile √© um arquivo que cont√©m um conjunto de diretivas para compilar e executar um projeto, automatizando tarefas repetitivas e simplificando a execu√ß√£o de comandos.

> **Pr√©-requisitos**
1. No arquivo Makefile, atribua o nome de usu√°rio do [Docker Hub](https://hub.docker.com/) √† vari√°vel `DOCKER_USER`. Isso permitir√° o envio da imagem modificada do Superset para o Docker Hub.
2. Atribua uma chave de API do [MapBox](https://www.mapbox.com/) √† vari√°vel `MAPBOX_API_KEY` para permitir a visualiza√ß√£o de mapas no Apache Superset. Essa atribui√ß√£o √© feita no arquivo `apps/superset/setup/docker/.env`.
2. Crie a rede `iot_analytics` no Docker usando o comando abaixo:
    ```bash
      make create-network
    ```

> **Configura√ß√£o para Execu√ß√£o**

1. Cria√ß√£o e execu√ß√£o dos containers das APIs:
    1.1 Gera√ß√£o das imagens das APIs:
    ```bash
      make apis-build
    ```
    1.2 Cria√ß√£o dos containers das APIs:
    ```bash
      make apis-run
    ```
    1.3 Execu√ß√£o dos containers das APIs:
    ```bash
      make apis-start
    ```
2. Gera√ß√£o e utiliza√ß√£o da imagem modificada do Superset:
    2.1 Gera√ß√£o da imagem:
    ```bash
      make superset-build
    ```
    2.2 Substitua a imagem do Superset no seu `docker-compose.yml` pela imagem gerada no passo anterior. Este arquivo est√° localizado em `apps/superset/setup`.

3. Cria√ß√£o e execu√ß√£o dos containers dos APPs:
    ```bash
      make apps-up
    ```
> **Executando**
1. Configura√ß√£o do Apache Kafka:
    1.1 Crie os t√≥picos listados abaixo, que s√£o utilizados para os fluxos de dados entre as aplica√ß√µes. Configure de acordo com sua necessidade, mas recomendo alocar 2 dias para os t√≥picos do tipo `raw` e 7 dias para os t√≥picos do tipo `processed`:
      * `raw_air_sensors_data`
      * `raw_air_sensors_historical_data`
      * `processed_air_sensors_status_data`
      * `processed_air_sensors_metrics_data`
      * `processed_air_sensors_historical_data`

2. Configura√ß√£o do Apache NiFi:
    2.1 Importe os templates localizados em `apps/nifi/src/templates`.
    2.2 Configure o DistributedMapCacheServer e o DistributedMapCacheClientService.
    2.3 Inicie os grupos de processos dos templates importados.

3. Configura√ß√£o do Apache Spark (execute cada comando em um terminal separado):
    3.1 Inicialize o processamento de dados brutos das m√©tricas captadas pelos sensores:
    ``` bash
    make spark-submit job=process_air_sensors_metrics_data
    ```
    3.2 Inicialize o processamento de dados brutos do status dos sensores:
    ``` bash
    make spark-submit job=process_air_sensors_status_data
    ```
    3.3 Inicialize o processamento de dados hist√≥ricos dos sensores:
    ``` bash
    make spark-submit job=process_air_sensors_historical_data
    ```
4. Configura√ß√£o do Apache Druid:
    4.1 Inicialize os processos de ingest√£o dos dados dos sensores, criando um processo de ingest√£o para cada `spec` localizado em `apps/druid/src/specs`.

5. Configura√ß√£o do Apache Superset:
    5.1 Importe os dashboards localizados em `apps/superset/src/dashboards`.

> **Finalizando**
1. Para finalizar a execu√ß√£o dos containers dos APPs:
    ```bash
      make apps-stop
    ```
2. Para finalizar a execu√ß√£o dos containers das APIs:
    ```bash
      make apis-stop
    ```

## üìÉ Licen√ßa <a name="license"></a>

Esse projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
